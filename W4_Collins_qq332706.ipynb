{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 4, Training Models\n",
    "\n",
    "In this assignment you will train different models on a given data set, and find the one that performs best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   longitude                 20640 non-null  float64\n",
      " 1   latitude                  20640 non-null  float64\n",
      " 2   housing_median_age        20640 non-null  float64\n",
      " 3   total_rooms               20640 non-null  float64\n",
      " 4   total_bedrooms            20640 non-null  float64\n",
      " 5   population                20640 non-null  float64\n",
      " 6   households                20640 non-null  float64\n",
      " 7   median_income             20640 non-null  float64\n",
      " 8   median_house_value        20640 non-null  float64\n",
      " 9   rooms_per_household       20640 non-null  float64\n",
      " 10  population_per_household  20640 non-null  float64\n",
      " 11  INLAND                    20640 non-null  uint8  \n",
      " 12  ISLAND                    20640 non-null  uint8  \n",
      " 13  LESS_1H_OCEAN             20640 non-null  uint8  \n",
      " 14  NEAR_BAY                  20640 non-null  uint8  \n",
      " 15  NEAR_OCEAN                20640 non-null  uint8  \n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "Using the familiar California housing dataset (target = 'median_house_value'), train several models using various regularization techniques to improve model accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Partition into train and test\n",
    "\n",
    "Use `train_test_split` from `sklearn.model_selection` to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_col = 'median_house_value'\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Polynomial transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PolynomialFeatures from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You should obtain X_train and X_test with 136 columns each, since originally you had 15 features.\n",
    "\n",
    "##### With m original features, the new added polynomial features of degree 2 are: $(m^2-m)/2+m+1$.\n",
    "\n",
    "##### These, plus the original features gives a total of  $(m^2-m)/2+2m+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original number of features: \"+str(len(features)))\n",
    "print(\"Final number of features: \"+str(X_tr.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use `StandardScaler` from `sklearn.preprocessing` to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models\n",
    "\n",
    "Use this function to display your cross val scores, or you may use your own custom function.\n",
    "\n",
    "**Either way it is important to display your results as you train new models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Linear regression on original features (no transformations) --- benchmark\n",
    "\n",
    "Train a simple linear regression model using `cross_val_score` with no regularization or feature transformations. This model will serve as your benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear regression  (on transformed features: polynomial transformation + scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do as in **2.1** but with the original and transformed features (136 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge regression\n",
    "\n",
    "Using the same transformed dataset from **2.2**, train another linear model but this time apply L2 regularization. Run the model through grid search to find the optimal regularization hyperparams. Print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lasso regression\n",
    "\n",
    "Now do the same as in **2.3** but with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Elastic Net regression\n",
    "\n",
    "Do the same as in **2.3** and **2.4**, but now with Elastic Net. However, the grid search should be over the parameters alpha and  L1 ratio. Use just 3 values for L1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Expected Results\n",
    "\n",
    "Before you compute the final_rmse on the test data using your best model, pause and reflect:\n",
    "- Does your best model have high variance? \n",
    "- Why was your best performing model better than the others?\n",
    "- What is your expected rmse score on your test data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluating your best model on TESTING data\n",
    "\n",
    "Of the models you created above, choose the best one to test on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "final_mse = mean_squared_error(y_test, YOUR_PREDICTIONS) # swap 'YOUR_PREDICTIONS' with the predictions values your model produces\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, YOUR_PREDICTIONS) # swap 'YOUR_PREDICTIONS' with the prediction values your model produces\n",
    "plt.xlim([-200000,800000])\n",
    "plt.ylim([-200000,800000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Try a more advanced model\n",
    "\n",
    "Try a more complex algorithm (SVR, RandomForest, etc.) and see if the accuracy improves (train on the full training set, and then test on the full test set). We have already done this in one of the earlier assignments so this should be easy!\n",
    "\n",
    "Why does the accuracy improve when using a more complex algorithm in this case? Write a very breif answer in the cell below following your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter α or reduce it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#[Optional]\n",
    "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
