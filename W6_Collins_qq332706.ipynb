{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 6\n",
    "\n",
    "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
    "\n",
    "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on original features (no transformations) --- benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Machines for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) In this exercise your goal is to tune SVR with RBF kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
    "\n",
    "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
    "\n",
    "However, as a hint, you can focus on C and gamma. \n",
    "\n",
    "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=4)]: Done  55 out of  60 | elapsed: 26.6min remaining:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done  57 out of  60 | elapsed: 30.7min remaining:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed: 43.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid=[{'C': array([1.00000000e+03, 2.78255940e+03, 7.74263683e+03, 2.15443469e+04,\n",
       "       5.99484250e+04, 1.66810054e+05, 4.64158883e+05, 1.29154967e+06,\n",
       "       3.59381366e+06, 1.00000000e+07]),\n",
       "                          'gamma': ['auto', 'scale']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=40)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "C_vals = np.logspace(3,7,10) ## YOUR VALUES FOR C ##\n",
    "gamma_vals = ['auto','scale'] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=3,scoring='neg_mean_squared_error', n_jobs=4, verbose=40)\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3593813.6638046256, 'gamma': 'auto'}\n",
      "55704.01859506022\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(np.sqrt(-grid_search_rbf.best_score_))\n",
    "#grid_search_rbf.cv_results_\n",
    "## LESS THAN 58000, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54277.2294653876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
    "\n",
    "y_te_estimation = final_model.predict(X_te)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM for Classification\n",
    "\n",
    "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(housing[['median_house_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
    "y_te_b = 1*np.ravel(y_te>=179700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384551495016611"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf=SVC(random_state=42)\n",
    "svc_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866140642303433"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc = svc_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred_svc)\n",
    "\n",
    "\n",
    "## Yes, it does improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m       \u001b[0mreciprocal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mType:\u001b[0m            reciprocal_gen\n",
       "\u001b[1;31mString form:\u001b[0m     <scipy.stats._continuous_distns.reciprocal_gen object at 0x0000018178E62F60>\n",
       "\u001b[1;31mFile:\u001b[0m            c:\\programdata\\anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py\n",
       "\u001b[1;31mDocstring:\u001b[0m      \n",
       "A reciprocal continuous random variable.\n",
       "\n",
       "As an instance of the `rv_continuous` class, `reciprocal` object inherits from it\n",
       "a collection of generic methods (see below for the full list),\n",
       "and completes them with details specific for this particular distribution.\n",
       "\n",
       "Methods\n",
       "-------\n",
       "rvs(a, b, loc=0, scale=1, size=1, random_state=None)\n",
       "    Random variates.\n",
       "pdf(x, a, b, loc=0, scale=1)\n",
       "    Probability density function.\n",
       "logpdf(x, a, b, loc=0, scale=1)\n",
       "    Log of the probability density function.\n",
       "cdf(x, a, b, loc=0, scale=1)\n",
       "    Cumulative distribution function.\n",
       "logcdf(x, a, b, loc=0, scale=1)\n",
       "    Log of the cumulative distribution function.\n",
       "sf(x, a, b, loc=0, scale=1)\n",
       "    Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n",
       "logsf(x, a, b, loc=0, scale=1)\n",
       "    Log of the survival function.\n",
       "ppf(q, a, b, loc=0, scale=1)\n",
       "    Percent point function (inverse of ``cdf`` --- percentiles).\n",
       "isf(q, a, b, loc=0, scale=1)\n",
       "    Inverse survival function (inverse of ``sf``).\n",
       "moment(n, a, b, loc=0, scale=1)\n",
       "    Non-central moment of order n\n",
       "stats(a, b, loc=0, scale=1, moments='mv')\n",
       "    Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n",
       "entropy(a, b, loc=0, scale=1)\n",
       "    (Differential) entropy of the RV.\n",
       "fit(data, a, b, loc=0, scale=1)\n",
       "    Parameter estimates for generic data.\n",
       "expect(func, args=(a, b), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
       "    Expected value of a function (of one argument) with respect to the distribution.\n",
       "median(a, b, loc=0, scale=1)\n",
       "    Median of the distribution.\n",
       "mean(a, b, loc=0, scale=1)\n",
       "    Mean of the distribution.\n",
       "var(a, b, loc=0, scale=1)\n",
       "    Variance of the distribution.\n",
       "std(a, b, loc=0, scale=1)\n",
       "    Standard deviation of the distribution.\n",
       "interval(alpha, a, b, loc=0, scale=1)\n",
       "    Endpoints of the range that contains alpha percent of the distribution\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The probability density function for `reciprocal` is:\n",
       "\n",
       ".. math::\n",
       "\n",
       "    f(x, a, b) = \\frac{1}{x \\log(b/a)}\n",
       "\n",
       "for :math:`a \\le x \\le b`, :math:`b > a > 0`.\n",
       "\n",
       "`reciprocal` takes :math:`a` and :math:`b` as shape parameters.\n",
       "\n",
       "The probability density above is defined in the \"standardized\" form. To shift\n",
       "and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n",
       "Specifically, ``reciprocal.pdf(x, a, b, loc, scale)`` is identically\n",
       "equivalent to ``reciprocal.pdf(y, a, b) / scale`` with\n",
       "``y = (x - loc) / scale``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from scipy.stats import reciprocal\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> fig, ax = plt.subplots(1, 1)\n",
       "\n",
       "Calculate a few first moments:\n",
       "\n",
       ">>> a, b = 0.00623, 1.01\n",
       ">>> mean, var, skew, kurt = reciprocal.stats(a, b, moments='mvsk')\n",
       "\n",
       "Display the probability density function (``pdf``):\n",
       "\n",
       ">>> x = np.linspace(reciprocal.ppf(0.01, a, b),\n",
       "...                 reciprocal.ppf(0.99, a, b), 100)\n",
       ">>> ax.plot(x, reciprocal.pdf(x, a, b),\n",
       "...        'r-', lw=5, alpha=0.6, label='reciprocal pdf')\n",
       "\n",
       "Alternatively, the distribution object can be called (as a function)\n",
       "to fix the shape, location and scale parameters. This returns a \"frozen\"\n",
       "RV object holding the given parameters fixed.\n",
       "\n",
       "Freeze the distribution and display the frozen ``pdf``:\n",
       "\n",
       ">>> rv = reciprocal(a, b)\n",
       ">>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
       "\n",
       "Check accuracy of ``cdf`` and ``ppf``:\n",
       "\n",
       ">>> vals = reciprocal.ppf([0.001, 0.5, 0.999], a, b)\n",
       ">>> np.allclose([0.001, 0.5, 0.999], reciprocal.cdf(vals, a, b))\n",
       "True\n",
       "\n",
       "Generate random numbers:\n",
       "\n",
       ">>> r = reciprocal.rvs(a, b, size=1000)\n",
       "\n",
       "And compare the histogram:\n",
       "\n",
       ">>> ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
       ">>> ax.legend(loc='best', frameon=False)\n",
       ">>> plt.show()\n",
       "\u001b[1;31mClass docstring:\u001b[0m\n",
       "A reciprocal continuous random variable.\n",
       "\n",
       "%(before_notes)s\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The probability density function for `reciprocal` is:\n",
       "\n",
       ".. math::\n",
       "\n",
       "    f(x, a, b) = \\frac{1}{x \\log(b/a)}\n",
       "\n",
       "for :math:`a \\le x \\le b`, :math:`b > a > 0`.\n",
       "\n",
       "`reciprocal` takes :math:`a` and :math:`b` as shape parameters.\n",
       "\n",
       "%(after_notes)s\n",
       "\n",
       "%(example)s\n",
       "\u001b[1;31mCall docstring:\u001b[0m \n",
       "Freeze the distribution for the given arguments.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "arg1, arg2, arg3,... : array_like\n",
       "    The shape parameter(s) for the distribution.  Should include all\n",
       "    the non-optional arguments, may include ``loc`` and ``scale``.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "rv_frozen : rv_frozen instance\n",
       "    The frozen distribution.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "?reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "C_vals = np.logspace(3,7,10) ## YOUR VALUES FOR C ##\n",
    "gamma_vals = ['auto','scale'] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = RandomizedSearchCV(SVC(random_state=42), param_grid, cv=3,scoring='neg_mean_squared_error', n_jobs=4, verbose=40)\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Train a Logistic Regression (search the best hyper-parameters) and compare its performance with SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
